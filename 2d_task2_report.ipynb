{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions for Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Prepare DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_targets(df, feature_names, target_names):\n",
    "    # used to get columns referring to features and target from a DataFrame\n",
    "    # feature_names and target_names must be lists\n",
    "    df_feature = df[feature_names]\n",
    "    df_target = df[target_names]\n",
    "    return df_feature, df_target\n",
    "\n",
    "def normalize_z(df):\n",
    "    # used to normalize features to allow computation of large data while maintaining relation ship with target variable\n",
    "    data = (df- df.mean())/df.std()\n",
    "    return data\n",
    "\n",
    "def polynomial_feature(df, col_name ,n):\n",
    "    df2 = df.copy()\n",
    "    k = 2\n",
    "    while k <= n:\n",
    "        new_col_name = col_name +'^' + str(k)\n",
    "        df2.loc[:, new_col_name] = df.loc[:,col_name] ** k \n",
    "        k += 1\n",
    "    return df2\n",
    "\n",
    "def prepare_feature(df_feature):\n",
    "    # adds a column of 1's and converts DataFrame to a np array to do matrix operations\n",
    "    ones = np.ones((df_feature.shape[0],1))\n",
    "    np_feature = np.concatenate((ones, df_feature), axis = 1)\n",
    "    return np_feature\n",
    "\n",
    "def prepare_target(df_target):\n",
    "    #converts df_target to np array\n",
    "    return df_target.values\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    #split df_feature, df_target to 2 sets for training and testing\n",
    "    indexes = df_feature.index\n",
    "    if random_state != None:\n",
    "        np.random.seed(random_state)\n",
    "    k = int(test_size * len(indexes))\n",
    "    test_index = np.random.choice(indexes,k, replace = False)\n",
    "    indexes = set(indexes)\n",
    "    test_index = set(test_index)\n",
    "    train_index = indexes - test_index\n",
    "    df_feature_train = df_feature.loc[train_index, :]\n",
    "    df_feature_test = df_feature.loc[test_index, :]\n",
    "    df_target_train = df_target.loc[train_index,:]\n",
    "    df_target_test = df_target.loc[test_index, :]\n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to apply Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, beta):\n",
    "    # computes the value of cost function (Average mean squared error)\n",
    "    J = 1/(2* len(X)) * np.sum(np.power(((X @ beta)- y), 2))\n",
    "    return J\n",
    "\n",
    "def gradient_descent(X, y, beta, alpha, num_iters):\n",
    "    # carrys out gradient descent to minimize cost function\n",
    "    J_storage = np.zeros(num_iters)\n",
    "    for i in range(num_iters):\n",
    "        beta = beta - (alpha/len(X)) * (X.T @ (X @ beta - y))\n",
    "        J_storage[i] = compute_cost(X, y, beta)\n",
    "    return beta, J_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_feature, beta):\n",
    "    # returns values of target_pred for a given test set of features\n",
    "    X_df = normalize_z(df_feature)\n",
    "    X = prepare_feature(X_df)\n",
    "    return predict_norm(X, beta)\n",
    "\n",
    "def predict_norm(X, beta):\n",
    "    # returns values of target_pred for a given test set of normalized features\n",
    "    return X @ beta\n",
    "\n",
    "def r2_score(y, ypred):\n",
    "    #calculates r2_score to determine strength of correlation\n",
    "    SS_res = np.sum(np.power((y - ypred), 2))\n",
    "    SS_tot = np.sum(np.power((y - y.mean()), 2))\n",
    "    return 1- SS_res/SS_tot\n",
    "\n",
    "def mean_squared_error(target, pred):\n",
    "    #returns sum of mean squared error\n",
    "    return np.sum(np.power((target - pred), 2))/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing csv\n",
    "df = pd.read_csv('archive\\covid19_sg.csv', parse_dates = ['Date'])\n",
    "\n",
    "#selecting required data\n",
    "df_select = df.loc[500:,:]\n",
    "df_select2 = df_select.copy()\n",
    "df_select2['days'] = df_select.loc[:,'Date'].apply(lambda x: (x- df_select.iloc[0,0]).days)\n",
    "\n",
    "# Getting columns corresponding to features and targets\n",
    "df_feature, df_target = get_features_targets(df_select2, ['days'] ,['Cumulative Confirmed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     days  days^2  days^3\n",
      "500     0       0       0\n",
      "501     1       1       1\n",
      "502     2       4       8\n",
      "503     3       9      27\n",
      "504     4      16      64\n"
     ]
    }
   ],
   "source": [
    "# setting up polynomial features\n",
    "df_features = polynomial_feature(df_feature, 'days', 3)\n",
    "#splitting test and training data\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = split_data(df_features, df_target, random_state=100, test_size= 0.3)\n",
    "#normalising feature\n",
    "df_features_train_z = normalize_z(df_features_train)\n",
    "#preparing features and targets as numpy arrays\n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2491d906d63d570839ae35d58aeeeaed6218054e2686ccc76c663abf85607b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
