{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions for Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Prepare DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_targets(df, feature_names, target_names):\n",
    "    # used to get columns referring to features and target from a DataFrame\n",
    "    # feature_names and target_names must be lists\n",
    "    df_feature = df[feature_names]\n",
    "    df_target = df[target_names]\n",
    "    return df_feature, df_target\n",
    "\n",
    "def normalize_z(df):\n",
    "    # used to normalize features to allow computation of large data while maintaining relation ship with target variable\n",
    "    data = (df- df.mean())/df.std()\n",
    "    return data\n",
    "\n",
    "def prepare_feature(df_feature):\n",
    "    # adds a column of 1's and converts DataFrame to a np array to do matrix operations\n",
    "    ones = np.ones((df_feature.shape[0],1))\n",
    "    np_feature = np.concatenate((ones, df_feature), axis = 1)\n",
    "    return np_feature\n",
    "\n",
    "def prepare_target(df_target):\n",
    "    #converts df_target to np array\n",
    "    return df_target.values\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    #split df_feature, df_target to 2 sets for training and testing\n",
    "    indexes = df_feature.index\n",
    "    if random_state != None:\n",
    "        np.random.seed(random_state)\n",
    "    k = int(test_size * len(indexes))\n",
    "    test_index = np.random.choice(indexes,k, replace = False)\n",
    "    indexes = set(indexes)\n",
    "    test_index = set(test_index)\n",
    "    train_index = indexes - test_index\n",
    "    df_feature_train = df_feature.loc[train_index, :]\n",
    "    df_feature_test = df_feature.loc[test_index, :]\n",
    "    df_target_train = df_target.loc[train_index,:]\n",
    "    df_target_test = df_target.loc[test_index, :]\n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to apply Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, beta):\n",
    "    # computes the value of cost function (Average mean squared error)\n",
    "    J = 1/(2* len(X)) * np.sum(np.power(((X @ beta)- y), 2))\n",
    "    return J\n",
    "\n",
    "def gradient_descent(X, y, beta, alpha, num_iters):\n",
    "    # carrys out gradient descent to minimize cost function\n",
    "    J_storage = np.zeros(num_iters)\n",
    "    for i in range(num_iters):\n",
    "        beta = beta - (alpha/len(X)) * (X.T @ (X @ beta - y))\n",
    "        J_storage[i] = compute_cost(X, y, beta)\n",
    "    return beta, J_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_feature, beta):\n",
    "    # returns values of target_pred for a given test set of features\n",
    "    X_df = normalize_z(df_feature)\n",
    "    X = prepare_feature(X_df)\n",
    "    return predict_norm(X, beta)\n",
    "\n",
    "def predict_norm(X, beta):\n",
    "    # returns values of target_pred for a given test set of normalized features\n",
    "    return X @ beta\n",
    "\n",
    "def r2_score(y, ypred):\n",
    "    #calculates r2_score to determine strength of correlation\n",
    "    SS_res = np.sum(np.power((y - ypred), 2))\n",
    "    SS_tot = np.sum(np.power((y - y.mean()), 2))\n",
    "    return 1- SS_res/SS_tot\n",
    "\n",
    "def mean_squared_error(target, pred):\n",
    "    #returns sum of mean squared error\n",
    "    return np.sum(np.power((target - pred), 2))/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing csv\n",
    "df = pd.read_csv('archive\\covid19_sg.csv', parse_dates = ['Date'])\n",
    "\n",
    "#selecting required data\n",
    "df_select = df.loc[500:,:]\n",
    "df_select2 = df_select.copy()\n",
    "df_select2['days'] = df_select.loc[:,'Date'].apply(lambda x: (x- df_select.iloc[0,0]).days)\n",
    "\n",
    "# Getting columns corresponding to features and targets\n",
    "df_feature, df_target = get_features_targets(df_select2, ['days'] ,['Cumulative Confirmed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2491d906d63d570839ae35d58aeeeaed6218054e2686ccc76c663abf85607b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
